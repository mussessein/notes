# MariaDB主从

MariaDB是MySQL的一个分之,完全兼容MySQL

这里节点的搭建,就不多说了,和Hadoop的集群搭建,基本一样;

具体的防火墙之类的,也不会再提及;

## 安装

- 主从节点尽量版本一致;
- 保证没有之前的数据库残留,卸载干净

我这里主节点是Deepin系统,从节点是CentOS 7.5

Deepin:

```sql
sudo apt-get install mariadb mariadb-server
```

CentOS:

```
sudo yum install mariadb-server
```

CentOS下,还需要继续配置:

将配置文件,放到/etc下

```shell
sudo cp /usr/share/mysql/my-huge.cnf /etc/my.cnf
```

执行脚本:完成密码的一些配置

```shell
/usr/bin/mysql_secure_installation
```

#### 启动服务

```
systemctl start mariadb
systemctl enable mariadb
```

## 配置

从节点修改server-id

主节点不需要修改

/etc/my.cnf

```shell
# 和主节点不同就行
server-id = 2
```

主从节点都配置一个,表明不区分大小写:

```
lower_case_table_names=1
```

## 创建主从复制用户

#### 1. 授权远程用户登录

让从节点可以登录到主节点中来,这里**主从都需要进行配置**

```sql
grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option;
```

#### 2. 创建主从复制用户

在主节点上建立账户并授权:slave

登录MariaDB

建立主从复制用户并授权

```sql
grant replication slave on *.* to 'slave'@'%' identified by 'slave';
```

#### 3. 查看mysql-bin.log

主从同步原理:

从节点通过更新mysql-bin.log,来执行sql语句,进行数据库同步

```sql
show master status;
```

如果查询结果为空,在配置文件中,添加:

```
log-bin=mysql-bin
```

## 配置从节点

#### 1. 授权远程用户登录

让从节点可以登录到主节点中来,这里**主从都需要进行配置**

```sql
grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option;
```

#### 2. 配置从节点

```sql
change master to MASTER_HOST='172.20.10.4',MASTER_USER='slave',MASTER_PASSWORD='slave',MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=313;
```

- MASTER_HOST:主节点IP
- MASTER_USER:登录主节点的用户
- MASTER_PASSWORD:登录主节点用户密码
- MASTER_LOG_FILE:mysql-bin.log文件,要与主节点一致
- MASTER_LOG_POS:position要与主节点一致

完成之后,开启从节点:

```sql
start slave
```

#### 3. 查看主从状态

```sql
show slave status;
-- 出现下面,即配置成功
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
```

# MyBatis读写分离

首先MySql要分库

其次，要读写分离，最起码要有两个数据源

- 写操作对主库（master）使用
- 读操作对从库（slave）使用

实现的主要思路：（非实现顺序）

1. 配置两个数据源（这里只配置两个数据源）
2. 区分两个数据源：将写和读分开
3. 定义标识（自定义注解）：通过注解，标识写操作和读操作，进行数据源的切换（底层是AOP）
4. 保证线程安全：一个业务逻辑一般同时包括读写，所以：在即时切换主从数据源的前提下，需要保证线程安全（threadLocal）
5. 配置MyBatis的sqlSessionFactory（实现动态切换两个数据源）

## 1. druid数据源配置

依赖：

```xml
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>druid</artifactId>
    <version>${druid.version}</version>
</dependency>
```

这里用yml文件配置：

主从数据源，基本配置一致

```yml
druid:
  type: com.alibaba.druid.pool.DruidDataSource
  master:
    url: jdbc:mysql://master:3306/mail?characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&useUnicode=true
    driver-class-name: com.mysql.jdbc.Driver
    username: root
    password: 123456
    initialSize: 5
    minIdle: 1
    #maxIdle: 10
    maxActive: 100
    maxWait: 60000
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    filters: stat,wall,log4j
    useGlobalDataSourceStat: true
  slave:
    url: jdbc:mysql://slave1:3306/mail?characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&useUnicode=true
    driver-class-name: com.mysql.jdbc.Driver
    username: root
    password: 123456
    initialSize: 5
    minIdle: 1
    #maxIdle: 10
    maxActive: 100
    maxWait: 60000
    timeBetweenEvictionRunsMillis: 60000
    minEvictableIdleTimeMillis: 300000
    validationQuery: SELECT 1 FROM DUAL
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    filters: stat,wall,log4j
    useGlobalDataSourceStat: true
```

## 2. 区分数据源

druid数据源的本身配置，写好了，但是SpringBoot并不认识druid数据源

我们要把druid注入到SpringBoot中，并且，对两个数据源进行区分

#### 1. DataSourceConfiguration

此类主要是将数据源进行区分为主数据源，从数据源

```java
@Configuration // 注入SpringBoot中
@EnableTransactionManagement
public class DataSourceConfiguration {
	private static Logger LOGGER = LoggerFactory.getLogger(DataSourceConfiguration.class);

	// 从yml中拿到type
	@Value("${druid.type}")
	private Class<? extends DataSource> dataSourceType;

	/**
	 * 配置master数据源(主库)
	 * @Bean:将此方法的返回对象,注入到SpringBoot中,即masterDataSource
	 * @ConfigurationProperties(prefix = "druid.master"):
	 * 将yml中的master的所有配置,注入到masterDataSource这个对象中
	 * @Primary:优先选择此对象,作为数据源,一般在主库的数据源上进行此标注
	 */
	@Bean(name = "masterDataSource")
	@Primary
	@ConfigurationProperties(prefix = "druid.master") 
	public DataSource masterDataSource() throws SQLException{
		DataSource masterDataSource = DataSourceBuilder.create().type(dataSourceType).build();
		LOGGER.info("========MASTER: {}=========", masterDataSource);
		return masterDataSource;
	}
	/**
	 * 同上,配置slave数据源
	 */
	@Bean(name = "slaveDataSource")
	@ConfigurationProperties(prefix = "druid.slave")
	public DataSource slaveDataSource(){
		DataSource slaveDataSource = DataSourceBuilder.create().type(dataSourceType).build();
		LOGGER.info("========SLAVE: {}=========", slaveDataSource);
		return slaveDataSource;
	}

	/**
	 * 定义druid的servlet,druid监控台
	 */
	@Bean
	public ServletRegistrationBean druidServlet() {
  	
		ServletRegistrationBean reg = new ServletRegistrationBean();
		// StatViewServlet:druid的servlet
		reg.setServlet(new StatViewServlet());
//      reg.setAsyncSupported(true);
		// 绑定监控台的url
		reg.addUrlMappings("/druid/*");
		// IP白名单:只允许localhost访问
		reg.addInitParameter("allow", "master");
		reg.addInitParameter("deny","slave1");
        reg.addInitParameter("loginUsername", "admin");
        reg.addInitParameter("loginPassword", "admin");
		LOGGER.info(" druid console manager init : {} ", reg);
		return reg;
  }
	/**
	 * 过滤器
	 */
	@Bean
	public FilterRegistrationBean filterRegistrationBean() {
		FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean();
		filterRegistrationBean.setFilter(new WebStatFilter());
		filterRegistrationBean.addUrlPatterns("/*");
		filterRegistrationBean.addInitParameter("exclusions", "*.js,*.gif,*.jpg,*.png,*.css,*.ico, /druid/*");
		LOGGER.info(" druid filter register : {} ", filterRegistrationBean);
		return filterRegistrationBean;
	}
}
```

#### 2. DataBaseContextHolder

此类是线程安全的进行主从数据源的切换（设置数据库操作的每个线程的数据源类型）

无论是主数据源，还是从数据源，之后是要交由MyBatis进行管理

所以MyBatis要获取某个操作的数据源类型：是主数据源，还是从数据源

通过此类，我们将每个数据源都设置一个ThreadLocal对象，即一个map<线程ID，DataBaseType>

来让MyBatis能够确定每个线程所操作的数据源类型

```java
public class DataBaseContextHolder {

	public enum DataBaseType {
		MASTER, SLAVE
	}
	private static final ThreadLocal<DataBaseType> contextHolder = new ThreadLocal<DataBaseType>();
	/**
	 * dataBaseType为空，默认使用主数据源
	 */
	public static void setDataBaseType(DataBaseType dataBaseType) {
		if(dataBaseType == null) throw new NullPointerException();
		contextHolder.set(dataBaseType);
	}
	// 获取数据源类型
	public static DataBaseType getDataBaseType(){
		return contextHolder.get() == null ? DataBaseType.MASTER : contextHolder.get();
	}
	// 清空ThreadLocal
	public static void clearDataBaseType(){
		contextHolder.remove();
	}
}
```

## 3. 配置MyBatis

#### 1. MybatisConfiguration

配置MyBatis，将数据源交由MyBatis管理

在Spring中是通过xml来配置的，在这里通过@Configuration注解，来实现

传统xml配置方式（通过bean标签来配置）：

1. 配置数据源：\<bean id="dataSource">
2. 配置sqlSessionFactory：\<bean id="sqlSessionFactory">
3. 事务管理：\<bean id="transactionManager">

我们这里使用JavaConfig方式来配置（继承MybatisAutoConfiguration）：

1. 配置数据源：是通过上面的DataSourceConfiguration这一个类配置的，在这里，只需要注入进来即可
2. 配置sqlSessionFactory：通过@Bean注入sqlSessionFactory（但是：这里导入的dataSource需要配置动态数据源，因为我们不止一个数据源）
3. 动态数据源：这就要用到之前的DataBaseContextHolder类，通过ThreadLocal来拿到这个线程到底是读还是写；

```java
@Configuration
@AutoConfigureAfter({DataSourceConfiguration.class})
public class MybatisConfiguration extends MybatisAutoConfiguration {
	/**
	 * 注入2个数据源
	 */
	@Resource(name="masterDataSource")
	private DataSource masterDataSource;

	@Resource(name="slaveDataSource")
	private DataSource slaveDataSource;
	
	@Bean(name="sqlSessionFactory")
	public SqlSessionFactory sqlSessionFactory() throws Exception {
		
		return super.sqlSessionFactory(roundRobinDataSourceProxy());
	}
	
	public AbstractRoutingDataSource roundRobinDataSourceProxy(){
		
		ReadWriteSplitRoutingDataSource proxy = new ReadWriteSplitRoutingDataSource();
		//数据源的map，里面装有master，slave
		SoftHashMap targetDataSource = new SoftHashMap();
		targetDataSource.put(DataBaseContextHolder.DataBaseType.MASTER, masterDataSource);
		targetDataSource.put(DataBaseContextHolder.DataBaseType.SLAVE, slaveDataSource);
		//设置默认数据源
		proxy.setDefaultTargetDataSource(masterDataSource);
		//装入两个主从数据源
		proxy.setTargetDataSources(targetDataSource);
		return proxy;
	}
}
```

#### 2. 动态数据源切换：

我们在使用某一个数据库操作的时候，需要知道到底是读操作，还是写操作，从而让MyBatis选择不同的数据源，进行此操作；

怎么才能知道是读，还是写，就是通过下面这个类，通过ThreadLocal来拿到操作类型；

需要继承AbstractRoutingDataSource类；

```java
public class ReadWriteSplitRoutingDataSource extends AbstractRoutingDataSource {
	@Override
	protected Object determineCurrentLookupKey() {
		return DataBaseContextHolder.getDataBaseType();
	}
}
```

## 3. 自定义注解

#### 1. 只读注解的声明

此注解的目的：声明数据库操作是只读的；

仅需要一个注解即可，没有进行标注的操作，默认为写操作；

```java
@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
public @interface ReadOnlyConnection {

}
```

- @Target({ElementType.METHOD, ElementType.TYPE})：表明此注解是在method上声明的
- @Retention(RetentionPolicy.RUNTIME)：运行策略为RunTime

#### 2. AOP切面实现

当写操作时，使用master数据源，当读操作时，使用slave数据源，这个操作是通过AOP实现的；

```java
@Aspect
@Component
public class ReadOnlyConnectionInterceptor implements Ordered {

	public static final Logger LOGGER = LoggerFactory.getLogger(ReadOnlyConnectionInterceptor.class);
	
	@Around("@annotation(readOnlyConnection)")
	public Object proceed(ProceedingJoinPoint proceedingJoinPoint, ReadOnlyConnection readOnlyConnection) throws Throwable {
		try{
			LOGGER.info("-----------set database connection 2 read only---------");
            // 将数据源更改为slave
	DataBaseContextHolder.setDataBaseType(DataBaseContextHolder.DataBaseType.SLAVE);
			// proceed():就是让标注此注解的原方法执行完毕
            Object result = proceedingJoinPoint.proceed();
			return result;
		} finally {
            // 数据操作完成之后，将ThreadLocal清空，不影响下次操作
			DataBaseContextHolder.clearDataBaseType();
			LOGGER.info("---------------clear database connection---------------");
		}
	}
	@Override
	public int getOrder() {
		return 0;
	}
}
```

#### 3. 添加注解的时机

某些业务方法，可能存在写操作和读操作；

这种情况，**就需要使用主库，同时进行写操作和读操作**，不可能分成两部分

即使分成两部分，主库写，从库读，是可能查询不到的，从库更新数据，是需要延迟的；

